{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-12T18:46:10.504687Z","iopub.status.busy":"2024-07-12T18:46:10.504311Z","iopub.status.idle":"2024-07-12T18:46:20.536144Z","shell.execute_reply":"2024-07-12T18:46:20.535315Z","shell.execute_reply.started":"2024-07-12T18:46:10.504657Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import torch\n","import torch.nn.functional as F\n","from torchvision import transforms\n","import time\n","import numpy as np\n","import os"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-12T18:48:30.657070Z","iopub.status.busy":"2024-07-12T18:48:30.656392Z","iopub.status.idle":"2024-07-12T18:48:30.665588Z","shell.execute_reply":"2024-07-12T18:48:30.664519Z","shell.execute_reply.started":"2024-07-12T18:48:30.657038Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found GPU at: /device:GPU:0\n","GPU available (YESS!!!!)\n"]}],"source":["\n","import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","\n","if \"GPU\" not in device_name:\n","    print(\"GPU device not found\")\n","    \n","print('Found GPU at: {}'.format(device_name))\n","\n","print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2024-07-12T19:12:51.662308Z","iopub.status.busy":"2024-07-12T19:12:51.661859Z","iopub.status.idle":"2024-07-12T21:11:41.122010Z","shell.execute_reply":"2024-07-12T21:11:41.120948Z","shell.execute_reply.started":"2024-07-12T19:12:51.662273Z"},"trusted":true},"outputs":[],"source":["# Load pretrained model\n","def load_model():\n","    try:\n","        model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', weights='DeepLabV3_ResNet101_Weights.DEFAULT', force_reload=True)\n","        print(\"Model has been loaded successfully.\")\n","        return model\n","    except Exception as e:\n","        print(f\"Error loading model: {e}\")\n","\n","model = load_model()\n","\n","# Segment people only for the purpose of human silhouette extraction\n","people_class = 15\n","\n","# Evaluate model\n","model.eval()\n","\n","blur = torch.FloatTensor([[[[1.0, 2.0, 1.0], [2.0, 4.0, 2.0], [1.0, 2.0, 1.0]]]]) / 16.0\n","\n","# Use GPU if supported, for better performance\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","if device == 'cuda':\n","    model.to(device)\n","    blur = blur.to(device)\n","\n","# Apply preprocessing (normalization)\n","preprocess = transforms.Compose([\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# Function to create segmentation mask\n","def makeSegMask(img):\n","    # Scale input frame\n","    frame_data = torch.FloatTensor(img) / 255.0\n","    input_tensor = preprocess(frame_data.permute(2, 0, 1))\n","    \n","    # Create mini-batch to be used by the model\n","    input_batch = input_tensor.unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        output = model(input_batch)['out'][0]\n","\n","    segmentation = output.argmax(0)\n","\n","    bgOut = output[0:1][:][:]\n","    a = (1.0 - F.relu(torch.tanh(bgOut * 0.30 - 1.0))).pow(0.5) * 2.0\n","\n","    people = segmentation.eq(torch.ones_like(segmentation).long().fill_(people_class)).float()\n","    people.unsqueeze_(0).unsqueeze_(0)\n","    \n","    for i in range(3):\n","        people = F.conv2d(people.to(device), blur, stride=1, padding=1)\n","\n","    # Activation function to combine masks - F.hardtanh(a * b)\n","    combined_mask = F.relu(F.hardtanh(a * (people.squeeze().pow(1.5))))\n","    combined_mask = combined_mask.expand(1, 3, -1, -1)\n","\n","    res = (combined_mask * 255.0).cpu().squeeze().byte().permute(1, 2, 0).numpy()\n","    return res\n","\n","# Define directories\n","input_dir = '/kaggle/input/original-data/Original_data'  # Update with your Kaggle input directory path\n","output_dir = '/kaggle/working/data_silhouette'  # Update with your Kaggle output directory path\n","\n","# Check if input directory exists\n","if not os.path.exists(input_dir):\n","    print(f\"Input directory {input_dir} does not exist.\")\n","else:\n","    print(f\"Input directory {input_dir} exists.\")\n","\n","# Create output directory if it doesn't exist\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","# Process videos\n","for subdir in os.listdir(input_dir):\n","    subdir_path = os.path.join(input_dir, subdir)\n","    if os.path.isdir(subdir_path):\n","        output_subdir = os.path.join(output_dir, subdir)\n","        \n","        if not os.path.exists(output_subdir):\n","            os.makedirs(output_subdir)\n","\n","        for filename in os.listdir(subdir_path):\n","            if filename.endswith('.mp4'):\n","                input_path = os.path.join(subdir_path, filename)\n","                output_path = os.path.join(output_subdir, f'output-{filename}')\n","\n","                print(f\"Processing video: {input_path}\")\n","\n","                # Loads video file into CV2\n","                video = cv2.VideoCapture(input_path)\n","                \n","                # Check if video opened successfully\n","                if not video.isOpened():\n","                    print(f\"Error opening video file {input_path}\")\n","                    continue\n","                \n","                # Get video file's dimensions\n","                frame_width = int(video.get(3))\n","                frame_height = int(video.get(4))\n","                \n","                # Creates output video file with XVID codec\n","                out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30, (frame_width, frame_height))\n","\n","                prev_frame_time = 0\n","                new_frame_time = 0\n","\n","                while video.isOpened():\n","                    # Read each frame one by one\n","                    success, img = video.read()\n","                    \n","                    # Run if there are still frames left\n","                    if success:\n","                        # Apply background subtraction to extract foreground (silhouette)\n","                        mask = makeSegMask(img)\n","                        \n","                        # Apply thresholding to convert mask to binary map\n","                        ret, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n","\n","                        # Write processed frame to output file\n","                        out.write(thresh)\n","                        \n","                        new_frame_time = time.time()\n","                        fps = 1 / (new_frame_time - prev_frame_time)\n","                        prev_frame_time = new_frame_time\n","                        fps = str(fps)\n","                        print(f\"Processing {filename} at {fps} FPS\")\n","                    # Break when there are no more frames  \n","                    else:\n","                        break\n","\n","                # Release resources\n","                video.release()\n","                out.release()\n","\n","print(\"Processing complete.\")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-12T21:17:36.229132Z","iopub.status.busy":"2024-07-12T21:17:36.228339Z","iopub.status.idle":"2024-07-12T21:17:40.623470Z","shell.execute_reply":"2024-07-12T21:17:40.622527Z","shell.execute_reply.started":"2024-07-12T21:17:36.229100Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Zipping complete.\n"]}],"source":["import shutil\n","\n","output_dir = '/kaggle/working/data_silhouette'\n","shutil.make_archive('/kaggle/working/data_silhouette', 'zip', output_dir)\n","print(\"Zipping complete.\")\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5379558,"sourceId":8940554,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
